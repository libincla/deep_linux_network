# confuse in working


## 过多的timewait
曾经: 服务器上过多（3w）的`TIME_WAIT`，使用`tcp_tw_reuse`和`tcp_tw_recycle`先解决了
思考: **一个`TIME_WAIT`状态的连接到底会有哪些开销**
     1. 到底是端口占用导致新连接无法建立 
     2. 还是过多消耗服务器上的内存
     3. 3w的`TIME_WAIT`算`warning`还是`error`


## 长连接开销
1. `redis`实例在开启长连接猴，出现了6000多条`TCP`连接，上线以后观察发现没有太大问题
思考: 吃不准一条空闲的`TCP`连接到底有多大的开销，引申
    1. 一台服务器最多可以支撑多少条`TCP`连接
       1. 是否有量化的估计
       2. 该数值 受`CPU`影响还是受内存大小限制
       3. 一台服务器可能支撑100w的并发长连接么
    2. 一台客户端最多可以支撑多少条`TCP`连接
       1. 客户端请求建立连接都是在`TCP`协议中占用一个16位的整数(0-65535)，是否意味着客户端单机最多只建立65535条连接
    3. 一条`TCP`连接需要消耗多大的内存?
       1. 一条`TCP`连接需要吃掉多少内存，是`KB`还是几十`KB`还是几`MB`


## CPU被消耗光(cpu使用率高但负载不是很高)
正常情况下，单个8核8g可以扛每秒2000左右的`QPS`，负载一直比较健康。
近期，偶发500状态的请求，通过`sar -u`查看峰值`CPU`余量只剩下20%~30%，负载不会很高

解决: 排查发现，原因是端口不充足情况下，`connect`系统调用的`CPU`消耗会大幅度增加。

**负载**指的是 就绪状态下等待`CPU`调用的进程数量统计，而服务器上进程又不多，所以自然负载不高

思考: 为什么在端口不足情况下，`connect`系统调用的`CPU`消耗会大幅度增加? 


## 不同语言网络性能差别巨大
1. `nginx`+`Lua`写的服务，差不多可以扛每秒2000`QPS`
2. `php-fpm`的服务，不到每秒500`QPS`
   
不同语言网络性能差别
1. 同步阻塞`IO`，分析阻塞在内核中到底是什么操作
2. `epoll`，多路复用之所以高性能的根本原因

## 127.0.0.1经过网卡么
随着`sidecar`模式兴起，本机网络`IO`应用逐步广泛，
思考: 本机网络`IO`执行过程是怎么样的，数据需要进入网卡么？性能是否有优势？节约了哪些开销?

